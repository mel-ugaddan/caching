# Caching
Caching is a fundamental systems design technique used to mitigate high-latency disk access and reduce network I/O in backend services. 
By storing frequently accessed or computationally expensive data in faster storage layers (typically memory), caching improves throughput, 
lowers tail latency, and increases overall system reliability. From a backend engineering perspective, caching 
is often a prerequisite for every scalable systems.
